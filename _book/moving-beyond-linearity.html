<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 4 Moving Beyond Linearity | Análisis Multivariado 2</title>
<meta name="author" content="Estudiante: Mauro Loprete, Profesora: Natalia Da Silva">
<meta name="description" content="Ejercicio 1 It was mentioned in the chapter that a cubic regression spline with one knot at \(\xi\) can be obtained using a basis of the form \(x\), \(x^{2}\), \(x^{3}\), \((x - \xi{})^{3}_{+}\)...">
<meta name="generator" content="bookdown 0.29 with bs4_book()">
<meta property="og:title" content="Capítulo 4 Moving Beyond Linearity | Análisis Multivariado 2">
<meta property="og:type" content="book">
<meta property="og:description" content="Ejercicio 1 It was mentioned in the chapter that a cubic regression spline with one knot at \(\xi\) can be obtained using a basis of the form \(x\), \(x^{2}\), \(x^{3}\), \((x - \xi{})^{3}_{+}\)...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 4 Moving Beyond Linearity | Análisis Multivariado 2">
<meta name="twitter:description" content="Ejercicio 1 It was mentioned in the chapter that a cubic regression spline with one knot at \(\xi\) can be obtained using a basis of the form \(x\), \(x^{2}\), \(x^{3}\), \((x - \xi{})^{3}_{+}\)...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Carpeta de ejercicios">Análisis Multivariado 2</a>:
        <small class="text-muted">Carpeta de ejercicios</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Sobre esta página</a></li>
<li><a class="" href="statistical-learning.html"><span class="header-section-number">2</span> Statistical learning</a></li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">3</span> Linear regression</a></li>
<li><a class="active" href="moving-beyond-linearity.html"><span class="header-section-number">4</span> Moving Beyond Linearity</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="laboratorio-con-tidymodels.html"><span class="header-section-number">5</span> Laboratorio con Tidymodels</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mauroloprete/multivariado2">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="moving-beyond-linearity" class="section level1" number="4">
<h1>
<span class="header-section-number">Capítulo 4</span> Moving Beyond Linearity<a class="anchor" aria-label="anchor" href="#moving-beyond-linearity"><i class="fas fa-link"></i></a>
</h1>
<div id="ejercicio-1-1" class="section level2 unnumbered">
<h2>Ejercicio 1<a class="anchor" aria-label="anchor" href="#ejercicio-1-1"><i class="fas fa-link"></i></a>
</h2>
<p><em>It was mentioned in the chapter that a cubic regression spline with one knot at <span class="math inline">\(\xi\)</span> can be obtained using a basis of the form <span class="math inline">\(x\)</span>, <span class="math inline">\(x^{2}\)</span>, <span class="math inline">\(x^{3}\)</span>, <span class="math inline">\((x - \xi{})^{3}_{+}\)</span> ,where <span class="math inline">\((x − \xi{})^{3}_{+} = (x − \xi)^{3}\)</span> <span class="math inline">\(if ~ x&gt; \xi\)</span> and equals 0 otherwise. We will now show that a function of the form</em></p>
<p><span class="math display">\[\begin{equation*}
    f(x) = \beta_{0} + \beta_{1}x + \beta_{2}x^{2} + \beta_{3}x^{3} + \beta_{4}(x-\xi{})^{3}_{+}
\end{equation*}\]</span></p>
<p><em>is indeed a cubic regression spline, regardless of the values of <span class="math inline">\(\beta_{0}\)</span>, <span class="math inline">\(\beta_{1}\)</span>, <span class="math inline">\(\beta_{2}\)</span>, <span class="math inline">\(\beta_{3}\)</span>, <span class="math inline">\(\beta_{4}\)</span>.</em></p>
<ul>
<li>
<p><strong>(a) Find a cubic polynomial</strong></p>
<p><span class="math display">\[\begin{equation*}
      f_{1}(x) = a_{1} + b_{1}x + c_{1}x^{2} + d_{1}x^{3}
  \end{equation*}\]</span></p>
<p><em>such that f(x)= f1(x) for all <span class="math inline">\(x \leq \xi{}\)</span>. Express <span class="math inline">\(a_{1}\)</span>,<span class="math inline">\(b_{1}\)</span>,<span class="math inline">\(c_{1}\)</span>,<span class="math inline">\(d_{1}\)</span> in terms of <span class="math inline">\(\beta_{0}\)</span>,<span class="math inline">\(\beta_{1}\)</span>, <span class="math inline">\(\beta_{2}\)</span>, <span class="math inline">\(\beta_{3}\)</span>, <span class="math inline">\(\beta_{4}\)</span></em></p>
<p>En este caso, al que la función <span class="math inline">\((x - \xi{})^{3}_{+}\)</span>, cada coeficiente corresponde a su análogo ordenados de mayor a menor, es decir <span class="math inline">\(a_{1} = \beta_{0}\)</span>, <span class="math inline">\(b_{1} = \beta_{1}\)</span>, <span class="math inline">\(c_{1} = \beta_{2}\)</span>, <span class="math inline">\(d_{1} = \beta_{3}\)</span></p>
</li>
<li>
<p><strong>(b) Find a cubic polynomial</strong></p>
<p><span class="math display">\[\begin{equation*}
      f_{2}(x) = a_{1} + b_{1}x + c_{1}x^{2} + d_{1}x^{3}
  \end{equation*}\]</span></p>
<p><em>such that f(x)= f2(x) for all <span class="math inline">\(x &gt; \xi{}\)</span>. Express <span class="math inline">\(a_{2}\)</span>,<span class="math inline">\(b_{2}\)</span>,<span class="math inline">\(c_{2}\)</span>,<span class="math inline">\(d_{2}\)</span> in terms of <span class="math inline">\(\beta_{0}\)</span>,<span class="math inline">\(\beta_{1}\)</span>, <span class="math inline">\(\beta_{2}\)</span>, <span class="math inline">\(\beta_{3}\)</span>, <span class="math inline">\(\beta_{4}\)</span> We have now established that f(x) is a piecewise polynomial.</em></p>
<p>En caso contrario a la parte anterior la función partida se activa, primero debemos desarrollar el término <span class="math inline">\((x-\xi{})^{3}\)</span> asociado a <span class="math inline">\(\beta_{4}\)</span></p>
<p><span class="math display">\[\begin{equation*}
      \beta_{4}(x-\xi{})^{3} = \left(x^{3} + -3x^{2} \xi{} +3x\xi{}^{2} - \xi{}^{3}\right)\beta_{4} = \beta_{4}x^{3} - 3\beta_{4}x^{2} \xi{} + 3\beta_{4}x\xi{}^{2} - \beta_{4}\xi{}^{3}
  \end{equation*}\]</span></p>
<p>Por lo tanto, remplazando en la especificación del modelo:</p>
<p><span class="math display">\[\begin{equation*}
      f(x) = \beta_{0} + \beta_{1}x + \beta_{2}x^{2} + \beta_{3}x^{3} + \beta_{4}x^{3} - 3\beta_{4}x^{2} \xi{} + 3\beta_{4}x\xi{}^{2} - \beta_{4}\xi{}^{3}
  \end{equation*}\]</span></p>
<p>Agrupando términos,</p>
<p><span class="math display">\[\begin{equation*}
      f(x) = \underbrace{(\beta_{0} - \beta_{4}\xi{}^{3})}_{a_{2}} + \overbrace{(\beta_{1} + 3\beta_{4}\xi{}^{3})x}^{b_{2}} + \underbrace{(\beta_{2} - 3\beta_{4}\xi{})x^{2} (\beta_{3}}_{c_{2}} + \overbrace{\beta_{4})x^{3}}^{d_{2}}
  \end{equation*}\]</span></p>
</li>
<li>
<p><strong>(c) Show that <span class="math inline">\(f_{1}(\xi{})= f_{2}(\xi{})\)</span>. That is, <span class="math inline">\(f(x)\)</span> is continuous at <span class="math inline">\(\xi{}\)</span></strong></p>
<p>Evaluando ambas expresiones:</p>
<p><span class="math display">\[\begin{equation*}
      f_{1}(\xi{}) = \beta_{0} + \beta_{1}\xi{} + \beta_{2}\xi{}^{2} + \beta_{3}\xi{}^{3}
  \end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
      f_{2}(\xi{}) = \beta_{0} + \beta_{1}\xi{} + \beta_{2}\xi{}^{2} + \beta_{3}\xi{}^{3}
  \end{equation*}\]</span></p>
<p>Por lo tanto, podemos asumir que el valor funcional en el salto y límite tanto por izquierda y derecha coinciden por lo tanto, la función es continua.</p>
</li>
<li>
<p><strong>(d) Show that <span class="math inline">\(f^{''}_{1}(\xi)=f^{''}_{2}(\xi)\)</span>. That is <span class="math inline">\(f^{''}(x)\)</span> is continuous at <span class="math inline">\(\xi\)</span>. Therefore, f(x) is indeed a cubic spline.</strong></p>
<p>Tomando primeras derivadas de cada expresión:</p>
<p><span class="math display">\[\begin{equation*}
      f^{'}_{1} =  \beta_{1} + 2\beta_{2}x + 3\beta_{3}x^{2}
  \end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
      f^{'}_{2} =  (\beta_{1} + 3\beta{4}\xi{}^{2}) + 2(\beta_{2} - 3\beta_{4}\xi)x + 3(\beta_{3} + \beta_{4})x^{2}
  \end{equation*}\]</span></p>
<p>Derivando nuevamente y evaluando:</p>
<p><span class="math display">\[\begin{equation*}
      f^{''}_{1} =  2\beta_{2} + 6\beta_{3}x \longrightarrow f^{''}_{1}(\xi) = 2\beta_{2} + 6\beta_{3}\xi
  \end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
      f^{''}_{2} =  2(\beta_{2}-\beta_{4})\xi + 6(\beta_{3} + \beta_{4})x \longrightarrow f^{''}_{2}(\xi{}) = 2\beta_{2} + 6\beta_{3}\xi
  \end{equation*}\]</span></p>
</li>
</ul>
</div>
<div id="ejercicio-2" class="section level2 unnumbered">
<h2>Ejercicio 2<a class="anchor" aria-label="anchor" href="#ejercicio-2"><i class="fas fa-link"></i></a>
</h2>
<p><em>Suppose that a curve <span class="math inline">\(\hat{g}\)</span> is computed to smoothly fit a set of n points using the following formula:</em></p>
<p><span class="math display">\[\begin{equation}
    \hat{g} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^{m}(x)\right]^{2}dx} \right)
\end{equation}\]</span></p>
<ul>
<li>
<p><strong>(a) <span class="math inline">\(\lambda = \infty\)</span>, <span class="math inline">\(m=0\)</span></strong></p>
<p>En este caso, la expresión anterior queda determinada de la siguiente manera:</p>
<p><span class="math display">\[\begin{equation}
      \hat{g} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^(x)\right]^{2}dx} \right)
  \end{equation}\]</span></p>
<p>Como la expresión debe ser finita, al que estamos frente a un valor extremo del parámetro de penalización la integral debe ser cero en todo su recorrido, por lo tanto <span class="math inline">\(g(x) = 0\)</span>.</p>
</li>
<li>
<p><strong>(b) <span class="math inline">\(\lambda = \infty\)</span>, <span class="math inline">\(m=1\)</span></strong></p>
<p>Nuevamente, al estar en el límite de <span class="math inline">\(\lambda\)</span>, revisemos la expresión</p>
<p><span class="math display">\[\begin{equation}
      \hat{g} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^(x)^{1}\right]^{2}dx} \right)
  \end{equation}\]</span></p>
<p>De forma análoga al se pide anterior, la derivada <span class="math inline">\(g^{'}(x) = 0\)</span>, entonces <span class="math inline">\(g(x) = c\)</span>.</p>
</li>
<li>
<p><strong>(c) <span class="math inline">\(\lambda = \infty\)</span>, <span class="math inline">\(m=2\)</span></strong></p>
<p><span class="math display">\[\begin{equation}
      \hat{g} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^(x)^{2}\right]^{2}dx} \right)
  \end{equation}\]</span></p>
<p>De forma análoga al se pide anterior, la derivada <span class="math inline">\(g^{''}(x) = 0\)</span>, entonces <span class="math inline">\(g(x) = ax+b\)</span>.</p>
</li>
<li>
<p><strong>(d) <span class="math inline">\(\lambda = \infty\)</span>, <span class="math inline">\(m=3\)</span></strong></p>
<p><span class="math display">\[\begin{equation}
      \hat{g} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^(x)^{3}\right]^{2}dx} \right)
  \end{equation}\]</span></p>
<p>De forma análoga al se pide anterior, la derivada <span class="math inline">\(g^{'''}(x) = 0\)</span>, entonces <span class="math inline">\(g(x) = ax^{2} + bx +c\)</span>.</p>
</li>
<li>
<p><strong>(e) <span class="math inline">\(\lambda = 0\)</span>, <span class="math inline">\(m=3\)</span></strong></p>
<p>En este caso, estamos frente a un spline cúbico sin suavizado y la estimación es por MCO.</p>
</li>
</ul>
</div>
<div id="ejercicio-3" class="section level2 unnumbered">
<h2>Ejercicio 3<a class="anchor" aria-label="anchor" href="#ejercicio-3"><i class="fas fa-link"></i></a>
</h2>
<p><em>Suppose we fit a curve with basis functions <span class="math inline">\(b_{1}(X) = X\)</span>, <span class="math inline">\(b_{2} = (X-1)^{2}I(X \leq 1)\)</span>. We fit the linear regression model</em></p>
<p><span class="math display">\[\begin{equation*}
    Y = \beta_{0} + \beta_{1}b_{1}(X) + \beta_{2}b_{2}(X) + \varepsilon
\end{equation*}\]</span></p>
<p><em>and obtain coefficient estiamtes <span class="math inline">\(\hat{\beta_{0}} = 1\)</span>, <span class="math inline">\(\hat{\beta_{1}} = 1\)</span>, <span class="math inline">\(\hat{\beta_{2}} = -2\)</span>. Sketch the estimated curve between <span class="math inline">\(X = −2\)</span> and <span class="math inline">\(X = 2\)</span>. Note the intercepts, slopes, and other relevant information</em></p>
<p>remplazando los coeficentes estimados, obtenemos la siguiente función de regresión:</p>
<p><span class="math display">\[\begin{equation*}
    \hat{f}(X) = 1 + X - 2(X-1)^{2}I(X \leq 1)
\end{equation*}\]</span></p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> <span class="op">+</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>,<span class="fl">2</span>,<span class="fl">0.01</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>,y <span class="op">=</span><span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>    <span class="va">df</span>,</span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span></span>
<span>    colour <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span></span>
<span>    xintercept <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    colour <span class="op">=</span> <span class="st">"green"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>    linetype <span class="op">=</span> <span class="st">"dashed"</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span></span>
<span>    <span class="st">"text"</span>,</span>
<span>    x <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>,</span>
<span>    y <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    label <span class="op">=</span> <span class="st">"f(x) = 1 +  x"</span>,</span>
<span>    parse <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span></span>
<span>    <span class="st">"text"</span>,</span>
<span>    x <span class="op">=</span> <span class="fl">1.5</span>,</span>
<span>    y <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    label <span class="op">=</span> <span class="st">"f(x) == -2*x^{2} +5 *x -1"</span>,</span>
<span>    parse <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span></span>
<span>    aspect.ratio <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-moving_beyond_linearity_files/figure-html/unnamed-chunk-1-1.png" width="672"></div>
<p>Es claro que a la izquierda de <span class="math inline">\(1\)</span> la función es una recta, por tanto su pendiente es uno. A la derecha,
la derivada es igual a <span class="math inline">\(f'(x) = -4x + 5\)</span>. La ordenada en el origen para la función de la izquierda es 1, mientras
que para la de la derecha es -1. En 1 la función es continua y derivable. La función obtiene su máximo en <span class="math inline">\(X = 5/4\)</span></p>
</div>
<div id="ejercicio-4-1" class="section level2 unnumbered">
<h2>Ejercicio 4<a class="anchor" aria-label="anchor" href="#ejercicio-4-1"><i class="fas fa-link"></i></a>
</h2>
<p><em>Suppose we fit a curve with basis functions <span class="math inline">\(b_{1}(X) = I(0 \leq X \leq 2) - (X-1)I(1 \leq X \leq 2)\)</span>, <span class="math inline">\(b_{2} = (X-3)I(3 \leq X \leq 4) + I(4 &lt; X \leq 5)\)</span>. We fit the linear regression model</em></p>
<p><span class="math display">\[\begin{equation*}
    Y = \beta_{0} + \beta_{1}b_{1}(X) + \beta_{2}b_{2}(X) + \varepsilon
\end{equation*}\]</span></p>
<p><em>and obtain coefficient estiamtes <span class="math inline">\(\hat{\beta_{0}} = 1\)</span>, <span class="math inline">\(\hat{\beta_{1}} = 1\)</span>, <span class="math inline">\(\hat{\beta_{2}} = 3\)</span>. Sketch the estimated curve between <span class="math inline">\(X = −2\)</span> and <span class="math inline">\(X = 2\)</span>. Note the intercepts, slopes, and other relevant information</em></p>
<p>La función de regresión puede escribirse como:</p>
<p><span class="math display">\[\begin{equation}
    \hat{f}(X) = 1 + I(0 \leq X \leq 2) - (X-1)I(1 \leq X \leq 2) + 3 \times (X-3)I(3 \leq X \leq 4) + I(4 &lt; X \leq 5)
\end{equation}\]</span></p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">-</span> <span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="fl">3</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">3</span> <span class="op">&amp;</span> <span class="va">x</span> <span class="op">&lt;=</span><span class="fl">4</span><span class="op">)</span> <span class="op">+</span> <span class="va">x</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">4</span> <span class="op">&amp;</span> <span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>,<span class="fl">2</span>,<span class="fl">0.01</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>,y <span class="op">=</span><span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span></span>
<span>    <span class="va">df</span>,</span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span></span>
<span>    colour <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span></span>
<span>    xintercept <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    colour <span class="op">=</span> <span class="st">"green"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>    linetype <span class="op">=</span> <span class="st">"dashed"</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span></span>
<span>    xintercept <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    colour <span class="op">=</span> <span class="st">"green"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>    linetype <span class="op">=</span> <span class="st">"dashed"</span></span>
<span><span class="op">)</span> <span class="op">+</span> </span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span></span>
<span>    xintercept <span class="op">=</span> <span class="fl">0</span>,</span>
<span>    colour <span class="op">=</span> <span class="st">"green"</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>    linetype <span class="op">=</span> <span class="st">"dashed"</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span></span>
<span>    aspect.ratio <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-moving_beyond_linearity_files/figure-html/unnamed-chunk-2-1.png" width="672"></div>
<p>A la izquierda de cero la pendiente vale cero, entre 0 y 1, la función es contante y vale 2, mientras que luego de 1 es una recta con pendiente unitaria negativa.</p>
</div>
<div id="ejercicio-5-1" class="section level2 unnumbered">
<h2>Ejercicio 5<a class="anchor" aria-label="anchor" href="#ejercicio-5-1"><i class="fas fa-link"></i></a>
</h2>
<p><em>Consider tow curves <span class="math inline">\(\hat{g}_{1}\)</span> and <span class="math inline">\(\hat{g}_{2}\)</span>, defined by</em></p>
<p><span class="math display">\[\begin{equation}
    \hat{g}_{1} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^{3}(x)\right]^{2}dx} \right)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
    \hat{g}_{2} = arg ~ min _{g} \left(\sum_{i}^{n}{\left(y_{i} - g(x_{i})\right)^{2}} + \lambda \int{\left[g^{4}(x)\right]^{2}dx} \right)
\end{equation}\]</span></p>
<ul>
<li>
<p><em>(a) As <span class="math inline">\(\lambda{} \rightarrow \infty\)</span>, will <span class="math inline">\(\hat{g}_{1}\)</span> or <span class="math inline">\(\hat{g}_{2}\)</span> have the smaller training RSS?</em></p>
<p>Las curvas resultantes resultan ser de órden cuadratíco y cúbico respectivamente, la segunda curva al tener un órden polinimico mayor es un modelo
mas flexible, por tanto, tiene un menor error de entrenamiento.</p>
</li>
<li>
<p><em>(b) As <span class="math inline">\(\lambda{} \rightarrow \infty\)</span>, will <span class="math inline">\(\hat{g}_{1}\)</span> or <span class="math inline">\(\hat{g}_{2}\)</span> have the smaller test RSS?</em></p>
<p>Depende de como sea la relación funcional y de los datos, en base a esto podemos afirmar quien tiene un mayor RSS fuera de la muestra de entrenamiento.</p>
</li>
<li>
<p><em>(c) As <span class="math inline">\(\lambda = 0\)</span>, will <span class="math inline">\(\hat{g}_{1}\)</span> or <span class="math inline">\(\hat{g}_{2}\)</span> have the smaller training and test RSS?</em></p>
<p>En este caso la restricción de suavizado no tiene efecto, por lo tanto <span class="math inline">\(\hat{g}_{1} = \hat{g_{2}}\)</span>, en consecuencia tienen el mismo RSS tanto en la muestra de entrenamiento y testing.</p>
</li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="linear-regression.html"><span class="header-section-number">3</span> Linear regression</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#moving-beyond-linearity"><span class="header-section-number">4</span> Moving Beyond Linearity</a></li>
<li><a class="nav-link" href="#ejercicio-1-1">Ejercicio 1</a></li>
<li><a class="nav-link" href="#ejercicio-2">Ejercicio 2</a></li>
<li><a class="nav-link" href="#ejercicio-3">Ejercicio 3</a></li>
<li><a class="nav-link" href="#ejercicio-4-1">Ejercicio 4</a></li>
<li><a class="nav-link" href="#ejercicio-5-1">Ejercicio 5</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mauroloprete/multivariado2/blob/master/03-moving_beyond_linearity.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mauroloprete/multivariado2/edit/master/03-moving_beyond_linearity.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Análisis Multivariado 2</strong>: Carpeta de ejercicios" was written by Estudiante: Mauro Loprete, Profesora: Natalia Da Silva. It was last built on 2022-10-09.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
